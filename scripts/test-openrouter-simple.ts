// Teste simples da API do OpenRouter
import dotenv from 'dotenv'

// Carregar vari√°veis de ambiente
dotenv.config()

async function testOpenRouter() {
  console.log('üß™ Testando conex√£o com OpenRouter...\n')
  
  const apiKey = process.env.OPENROUTER_API_KEY
  
  if (!apiKey) {
    console.error('‚ùå OPENROUTER_API_KEY n√£o encontrada!')
    return
  }
  
  console.log('üîë API Key encontrada:', apiKey.substring(0, 20) + '...')
  
  try {
    // Testar endpoint de modelos
    console.log('\nüìã Testando lista de modelos...')
    const modelsResponse = await fetch('https://openrouter.ai/api/v1/models', {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    })
    
    if (!modelsResponse.ok) {
      console.error('‚ùå Erro ao buscar modelos:', modelsResponse.status, modelsResponse.statusText)
      return
    }
    
    const modelsData = await modelsResponse.json()
    console.log('‚úÖ Modelos encontrados:', modelsData.data?.length || 0)
    
    // Mostrar alguns modelos importantes
    const importantModels = [
      'openai/gpt-4o-mini',
      'anthropic/claude-3.5-sonnet',
      'google/gemini-2.0-flash-exp',
      'deepseek/deepseek-chat',
      'meta-llama/llama-3.2-90b-vision-instruct'
    ]
    
    console.log('\nüéØ Verificando modelos importantes:')
    for (const modelId of importantModels) {
      const found = modelsData.data?.find((m: any) => m.id === modelId)
      if (found) {
        console.log(`‚úÖ ${modelId} - Dispon√≠vel`)
      } else {
        console.log(`‚ùå ${modelId} - N√£o encontrado`)
      }
    }
    
    // Testar uma requisi√ß√£o simples
    console.log('\nüí¨ Testando chat simples...')
    const chatResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://innerai-clone.com',
        'X-Title': 'InnerAI Clone'
      },
      body: JSON.stringify({
        model: 'openai/gpt-4o-mini',
        messages: [
          {
            role: 'user',
            content: 'Responda apenas "OK" se voc√™ est√° funcionando.'
          }
        ],
        max_tokens: 10
      })
    })
    
    if (!chatResponse.ok) {
      console.error('‚ùå Erro no chat:', chatResponse.status, chatResponse.statusText)
      const errorText = await chatResponse.text()
      console.error('Detalhes:', errorText)
      return
    }
    
    const chatData = await chatResponse.json()
    const response = chatData.choices?.[0]?.message?.content
    
    if (response) {
      console.log('‚úÖ Chat funcionando! Resposta:', response.trim())
    } else {
      console.log('‚ö†Ô∏è Chat retornou resposta vazia')
    }
    
    console.log('\nüéâ Teste conclu√≠do com sucesso!')
    
  } catch (error) {
    console.error('‚ùå Erro durante o teste:', error)
  }
}

// Executar teste
testOpenRouter().catch(console.error)